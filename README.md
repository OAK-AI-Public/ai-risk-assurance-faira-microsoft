# ai-risk-assurance-faira-microsoft

## üõ°Ô∏è Unified AI Risk Assurance Framework

A practical synthesis of the **Queensland Government FAIRA Framework (v1.0.0)** and the **Microsoft AI Security Risk Assessment**, designed to help public sector teams deploy artificial intelligence solutions securely, ethically, and in compliance with national policy and WHS obligations.

Published by **[OAK AI](https://github.com/OAK-AI-Public)**  
GitHub Repository: [OAK-AI-Public/ai-risk-assurance-faira-microsoft](https://github.com/OAK-AI-Public/ai-risk-assurance-faira-microsoft)

**Latest Update**: Enhanced with NIST AI Security Competency Area integration, adding 46 AI-specific competencies (39 knowledge areas + 7 skills) for comprehensive AI security capability assessment. Now includes the Australian Responsible AI Index 2025 (NAIC/Fifth Quadrant) for maturity benchmarking aligned with VAISS.

---

## üìò What‚Äôs Inside

This guide combines:

- ‚úÖ [FAIRA Framework](https://www.forgov.qld.gov.au/information-technology/queensland-government-enterprise-architecture-qgea/qgea-directions-and-guidance/qgea-policies-standards-and-guidelines/faira-framework) ‚Äì a values-based risk and governance framework for AI in Queensland Government
- üîê [Microsoft AI Security Risk Assessment](https://learn.microsoft.com/en-us/security/ai-red-team/ai-risk-assessment) ([PDF](https://github.com/MicrosoftDocs/security/blob/main/Downloads/AI_Risk_Assessment_v4.1.4.pdf)) ‚Äì practical lifecycle security controls for AI systems
- ‚öñÔ∏è Alignment with the [NFAAIG (2024)](https://www.dta.gov.au/help-and-advice/emerging-technologies/artificial-intelligence-ai/assurance-framework) and QLD legislation
- ‚ö†Ô∏è Integration of **Workplace Health and Safety (WHS)** impacts under the _WHS Act 2011_
- üéØ Integration of [NIST AI Security Competency Area](https://www.nist.gov/itl/applied-cybersecurity/nice/nice-framework-resource-center) ‚Äì 46 AI-specific competencies for security teams
- üá¶üá∫ **NEW**: [Australian Responsible AI Index 2025](./frameworks/naic-rai-index-2025.md) (NAIC/Fifth Quadrant) ‚Äì benchmarking tool aligned with VAISS for Responsible AI maturity assessment

---

## üß≠ Use This Guide To

- Evaluate AI solutions with ethics, transparency and risk in mind
- Design and document controls across development, deployment and use
- Embed WHS, privacy, contestability and security into AI lifecycles
- Align with QLD GOV ICT, procurement and executive governance frameworks

---

## üìÇ Files

| File                                     | Description                                                      |
| ---------------------------------------- | ---------------------------------------------------------------- |
| `Unified_AI_Risk_Assurance_Framework.md` | The full synthesis guide (read this first)                       |
| `AI_Risk_Assurance_Checklists.md`        | Practical checklists for implementing the framework step-by-step |
| `FAIRA_Framework.md`                     | Queensland Government FAIRA Framework (extracted from DOCX)      |
| `AI_Security_Risk_Assessment.md`         | Microsoft AI Security Risk Assessment (extracted from PDF)       |
| `frameworks/naic-rai-index-2025.md`     | Australian Responsible AI Index 2025 (NAIC/Fifth Quadrant)       |
| `mappings/naic-rai-index-2025.yaml`     | NAIC RAI Index taxonomy mappings and cross-framework alignment   |
| `Figure_1.webp`                          | FAIRA Framework diagram - How FAIRA Works                        |
| `Figure_2.webp`                          | FAIRA Framework diagram - Components of an AI solution           |
| `LICENSE`                                | MIT License with third-party licence attribution                 |
| `README.md`                              | Overview and repository index                                    |

---

## üîç References

- FAIRA Framework: ¬© The State of Queensland 2024  
  [Licence: CC BY 4.0](http://creativecommons.org/licenses/by/4.0/)
- Microsoft AI Risk Assessment: ¬© Microsoft Corporation  
  [GitHub Repo](https://github.com/MicrosoftDocs/security)
- NIST AI Security Competency Area: National Institute of Standards and Technology  
  Special thanks to [Ben Kereopa-Yorke](https://www.linkedin.com/in/benkereopayorke/) for highlighting the NIST AI Security Competency Area framework
- Australian Responsible AI Index 2025: ¬© Fifth Quadrant / National AI Centre  
  [Framework Homepage](https://www.fifthquadrant.com.au/responsible-ai-index) | [NAIC News](https://www.industry.gov.au/news/benchmark-your-responsible-ai-maturity-level-new-self-assessment-tool)

---

## üì¨ Contributions & Feedback

This guide is open and evolving. If you have suggestions or corrections:

- [Open an issue](https://github.com/OAK-AI-Public/ai-risk-assurance-faira-microsoft/issues)
- Or contact the maintainers via [OAK AI](https://github.com/OAK-AI-Public)

---

## üìÑ Licence

MIT Licence with proper attribution to QLD Government FAIRA and Microsoft AI Risk Assessment. See [`LICENSE`](./LICENSE) for full details.
