# Australian Responsible AI Index 2025

**National AI Centre (NAIC) / Fifth Quadrant Framework**

## Overview

The Australian Responsible AI Index 2025 is a comprehensive framework that provides in-depth analysis of how Australian organisations adopt and implement Responsible AI practices. This fourth iteration of the index is aligned with Australia's Voluntary AI Safety Standard (VAISS) and offers organisations a practical tool for benchmarking their Responsible AI maturity.

## Framework Details

### Origins & Sponsors

- **Concept Creator**: Dr Catriona Wallace
- **Implementation**: Fifth Quadrant  
- **Sponsor**: Australia's National AI Centre (Department of Industry, Science & Resources)
- **Edition**: Fourth iteration (2025 edition)

### Scope & Methodology

The index is based on a comprehensive survey of **418 AI decision-makers** across Australian organisations with 20 or more employees. The survey assesses Responsible AI maturity across multiple dimensions, providing insights into current practices and trends in the Australian AI landscape.

### VAISS Alignment

The 2025 edition has been updated to align with Australia's **Voluntary AI Safety Standard (VAISS)**, which defines ten critical guardrails for AI systems:

1. **Accountability & Governance** - Clear ownership and decision-making structures
2. **Risk Management** - Systematic identification and mitigation of AI risks  
3. **Data Governance & Protection** - Responsible data handling and privacy protection
4. **Testing & Monitoring** - Continuous evaluation of AI system performance
5. **Human Oversight** - Meaningful human control and intervention capabilities
6. **Transparency** - Clear communication about AI system operations
7. **Contestability** - Mechanisms for challenging AI-driven decisions
8. **Supply Chain Transparency** - Understanding of AI component origins and dependencies
9. **Compliance** - Adherence to relevant laws and regulations
10. **Stakeholder Engagement** - Inclusive consultation with affected parties

## Assessment Dimensions

The index tracks Responsible AI maturity across **five key dimensions**:

### 1. Accountability & Oversight (13 practices)
Covers governance structures, leadership accountability, and organisational responsibility for AI systems.

### 2. Safety & Resilience (11 practices)  
Addresses risk management, system reliability, and protection against potential harms.

### 3. Fairness (7 practices)
Focuses on bias prevention, equitable outcomes, and non-discrimination in AI applications.

### 4. Transparency (8 practices)
Encompasses clear communication, explainable processes, and stakeholder understanding.

### 5. Explainability & Contestability (6 practices)
Covers the ability to understand AI decisions and provide mechanisms for challenge and appeal.

## Scoring Methodology

The index uses a standardised scoring approach:

- **Implemented practices**: 2 points
- **Planned practices**: 1 point  
- **Neither implemented nor planned**: 0 points

Each dimension is **weighted equally** to calculate a total score out of **100 points**, providing a comprehensive maturity assessment.

## Maturity Levels

Organisations are categorised into four maturity levels based on their total score:

### Emerging (0–24 points)
- Minimal implementation of Responsible AI practices
- Limited oversight and leadership support
- Basic or no formal AI governance structures

### Developing (25–49 points)  
- Partial progress in Responsible AI adoption
- Introduction of transparency, explainability and contestability initiatives
- Growing awareness and initial implementation efforts

### Implementing (50–69 points)
- Broader implementation across multiple dimensions
- Focus on stakeholder engagement, auditing, ethics and data security
- Systematic approach to Responsible AI practices

### Leading (70+ points)
- Extensive Responsible AI adoption across all dimensions
- Leadership-driven accountability and strategic integration
- Comprehensive governance and mature implementation

## 2025 Findings

### Overall Results
- **Mean score**: 43/100 (down one point from 2024)
- This indicates most Australian organisations are in the "Developing" stage

### Maturity Distribution
- **Emerging (0-24)**: 17% of organisations
- **Developing (25-49)**: 48% of organisations  
- **Implementing (50-69)**: 23% of organisations
- **Leading (70+)**: 12% of organisations

### Key Insights
- **Experience drives maturity**: Organisations with ≥4 years of AI experience average **54 points** compared to **42 points** for those with <4 years
- **Organisational size matters**: Larger organisations tend to have higher maturity scores
- The slight decline from 2024 suggests the need for continued focus on Responsible AI implementation

## Self-Assessment Tool

The framework includes a self-assessment tool that provides organisations with:

- **Personalised maturity score** based on the five dimensions
- **Peer benchmarking** against similar organisations  
- **Tailored guidance** for improving Responsible AI practices
- **Actionable recommendations** for progression to higher maturity levels

## Integration with Other Frameworks

This framework complements existing AI governance approaches and can be used alongside:

- [Queensland Government FAIRA Framework](../FAIRA_Framework.md)
- [Microsoft AI Security Risk Assessment](../AI_Security_Risk_Assessment.md)
- NIST AI Risk Management Framework
- OECD AI Principles
- EU AI Act requirements

## Implementation Guidance

Organisations can use this framework to:

1. **Benchmark current state** using the self-assessment tool
2. **Identify gaps** across the five key dimensions
3. **Develop improvement plans** based on maturity level recommendations
4. **Track progress** over time through regular re-assessment
5. **Compare performance** with industry peers and best practices

## Sources & Further Information

- **NAIC News**: [Benchmark your Responsible AI maturity level with a new self-assessment tool](https://www.industry.gov.au/news/benchmark-your-responsible-ai-maturity-level-new-self-assessment-tool) - Australian Department of Industry, Science & Resources
- **Framework Homepage**: [Responsible AI Index 2025](https://www.fifthquadrant.com.au/responsible-ai-index) - Fifth Quadrant
- **Executive Summary**: [Australian Responsible AI Index 2025 Executive Summary (PDF)](https://www.fifthquadrant.com.au/content/uploads/Australian-Responsible-AI-Index-2025_Executive-Summary.pdf) - Fifth Quadrant
- **Full Report**: [Australian Responsible AI Index 2025 Full Report (PDF)](https://www.fifthquadrant.com.au/content/uploads/Australian-Responsible-AI-Index-2025_Full-Report.pdf) - Fifth Quadrant (26 Aug 2025)

---

## Document Information

**Framework**: Australian Responsible AI Index 2025  
**Version**: 2025 Edition  
**Publisher**: Fifth Quadrant / National AI Centre  
**Last Updated**: August 2025  
**Integration Date**: August 2025

---

*This framework description is part of the [Unified AI Risk Assurance Framework](../README.md) maintained by [OAK AI](https://github.com/OAK-AI-Public).*